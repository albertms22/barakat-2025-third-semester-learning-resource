# ============================================
# PART 1: USING RAW RESOURCES (The Hard Way)
# ============================================

# main.tf - Creating VPC infrastructure with raw resources
resource "aws_vpc" "main" {
  cidr_block           = "10.0.0.0/16"
  enable_dns_hostnames = true
  enable_dns_support   = true

  tags = {
    Name = "my-vpc"
  }
}

resource "aws_subnet" "public" {
  vpc_id                  = aws_vpc.main.id
  cidr_block              = "10.0.1.0/24"
  availability_zone       = "us-east-1a"
  map_public_ip_on_launch = true

  tags = {
    Name = "public-subnet"
  }
}

resource "aws_internet_gateway" "main" {
  vpc_id = aws_vpc.main.id

  tags = {
    Name = "main-igw"
  }
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.main.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.main.id
  }

  tags = {
    Name = "public-rt"
  }
}

resource "aws_route_table_association" "public" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}

# ============================================
# PART 2: THE SAME THING AS A MODULE
# ============================================

# modules/simple-vpc/main.tf
# This file would be in modules/simple-vpc/main.tf

resource "aws_vpc" "this" {
  cidr_block           = var.vpc_cidr
  enable_dns_hostnames = var.enable_dns_hostnames
  enable_dns_support   = var.enable_dns_support

  tags = merge(
    var.tags,
    {
      Name = var.vpc_name
    }
  )
}

resource "aws_subnet" "public" {
  vpc_id                  = aws_vpc.this.id
  cidr_block              = var.public_subnet_cidr
  availability_zone       = var.availability_zone
  map_public_ip_on_launch = var.map_public_ip_on_launch

  tags = merge(
    var.tags,
    {
      Name = "${var.vpc_name}-public-subnet"
    }
  )
}

resource "aws_internet_gateway" "this" {
  vpc_id = aws_vpc.this.id

  tags = merge(
    var.tags,
    {
      Name = "${var.vpc_name}-igw"
    }
  )
}

resource "aws_route_table" "public" {
  vpc_id = aws_vpc.this.id

  route {
    cidr_block = "0.0.0.0/0"
    gateway_id = aws_internet_gateway.this.id
  }

  tags = merge(
    var.tags,
    {
      Name = "${var.vpc_name}-public-rt"
    }
  )
}

resource "aws_route_table_association" "public" {
  subnet_id      = aws_subnet.public.id
  route_table_id = aws_route_table.public.id
}

# modules/simple-vpc/variables.tf

variable "vpc_cidr" {
  description = "CIDR block for VPC"
  type        = string
}

variable "vpc_name" {
  description = "Name of the VPC"
  type        = string
}

variable "public_subnet_cidr" {
  description = "CIDR block for public subnet"
  type        = string
}

variable "availability_zone" {
  description = "Availability zone for subnet"
  type        = string
}

variable "enable_dns_hostnames" {
  description = "Enable DNS hostnames in VPC"
  type        = bool
  default     = true
}

variable "enable_dns_support" {
  description = "Enable DNS support in VPC"
  type        = bool
  default     = true
}

variable "map_public_ip_on_launch" {
  description = "Auto-assign public IP to instances"
  type        = bool
  default     = true
}

variable "tags" {
  description = "Tags to apply to all resources"
  type        = map(string)
  default     = {}
}

# modules/simple-vpc/outputs.tf

output "vpc_id" {
  description = "ID of the VPC"
  value       = aws_vpc.this.id
}

output "public_subnet_id" {
  description = "ID of the public subnet"
  value       = aws_subnet.public.id
}

output "internet_gateway_id" {
  description = "ID of the internet gateway"
  value       = aws_internet_gateway.this.id
}

# ============================================
# PART 3: USING THE MODULE (The Easy Way)
# ============================================

# main.tf - Now we just call the module!

module "vpc" {
  source = "./modules/simple-vpc"

  vpc_cidr           = "10.0.0.0/16"
  vpc_name           = "my-vpc"
  public_subnet_cidr = "10.0.1.0/24"
  availability_zone  = "us-east-1a"

  tags = {
    Environment = "dev"
    ManagedBy   = "terraform"
  }
}

# Access module outputs
output "vpc_id" {
  value = module.vpc.vpc_id
}

output "public_subnet_id" {
  value = module.vpc.public_subnet_id
}

# ============================================
# PART 4: USING A REMOTE MODULE FROM TERRAFORM REGISTRY
# ============================================

# Using the official terraform-aws-modules/vpc/aws module
# This is the most popular VPC module with 10M+ downloads
# Source: https://registry.terraform.io/modules/terraform-aws-modules/vpc/aws

module "vpc_from_registry" {
  source  = "terraform-aws-modules/vpc/aws"
  version = "5.1.2"  # Always pin to a specific version

  # Basic configuration
  name = "my-vpc-from-registry"
  cidr = "10.0.0.0/16"

  # Subnets across availability zones
  azs             = ["us-east-1a", "us-east-1b"]
  public_subnets  = ["10.0.1.0/24", "10.0.2.0/24"]
  private_subnets = ["10.0.11.0/24", "10.0.12.0/24"]

  # Enable NAT Gateway for private subnets
  enable_nat_gateway = true
  single_nat_gateway = true  # Use one NAT for cost savings in dev

  # DNS settings
  enable_dns_hostnames = true
  enable_dns_support   = true

  # Tags
  tags = {
    Environment = "dev"
    ManagedBy   = "terraform"
  }

  public_subnet_tags = {
    Type = "public"
  }

  private_subnet_tags = {
    Type = "private"
  }
}

# Access outputs from the registry module
output "registry_vpc_id" {
  description = "VPC ID from registry module"
  value       = module.vpc_from_registry.vpc_id
}

output "registry_public_subnets" {
  description = "Public subnet IDs from registry module"
  value       = module.vpc_from_registry.public_subnets
}

output "registry_private_subnets" {
  description = "Private subnet IDs from registry module"
  value       = module.vpc_from_registry.private_subnets
}

output "registry_nat_gateway_ids" {
  description = "NAT Gateway IDs"
  value       = module.vpc_from_registry.natgw_ids
}

# ============================================
# KEY DIFFERENCES: Local vs Remote Modules
# ============================================

# LOCAL MODULE (Part 3):
# - source = "./modules/simple-vpc"  (file path)
# - You control the code
# - Changes immediately reflected
# - Good for: Custom logic, learning, organization-specific patterns

# REMOTE MODULE (Part 4):
# - source = "terraform-aws-modules/vpc/aws"  (registry path)
# - version = "5.1.2"  (version pinning required)
# - Maintained by community
# - Must run 'terraform init' to download
# - Good for: Battle-tested code, common patterns, saving time

# Behind the scenes, the registry module uses the SAME resources:
# - aws_vpc
# - aws_subnet
# - aws_internet_gateway
# - aws_nat_gateway
# - aws_route_table
# - aws_route_table_association
# ...plus many more features and configurations!


# ============================================
# STEP 1: CREATE AWS RESOURCES FOR REMOTE BACKEND
# ============================================

# backend-resources.tf
# Run this FIRST with local backend to create the S3 bucket and DynamoDB table

terraform {
  # Leave backend empty initially or use local backend
  # We'll configure this after creating the resources
}

provider "aws" {
  region = "us-east-1"
}

# S3 bucket for storing terraform state
resource "aws_s3_bucket" "terraform_state" {
  bucket = "my-terraform-state-bucket-12345"  # Must be globally unique!

  tags = {
    Name        = "Terraform State Bucket"
    Environment = "shared"
  }
}

# Enable versioning to keep history of state files
resource "aws_s3_bucket_versioning" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id

  versioning_configuration {
    status = "Enabled"
  }
}

# Enable encryption at rest
resource "aws_s3_bucket_server_side_encryption_configuration" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id

  rule {
    apply_server_side_encryption_by_default {
      sse_algorithm = "AES256"
    }
  }
}

# Block public access to the bucket
resource "aws_s3_bucket_public_access_block" "terraform_state" {
  bucket = aws_s3_bucket.terraform_state.id

  block_public_acls       = true
  block_public_policy     = true
  ignore_public_acls      = true
  restrict_public_buckets = true
}

# DynamoDB table for state locking
resource "aws_dynamodb_table" "terraform_locks" {
  name         = "terraform-state-locks"
  billing_mode = "PAY_PER_REQUEST"
  hash_key     = "LockID"

  attribute {
    name = "LockID"
    type = "S"
  }

  tags = {
    Name        = "Terraform State Lock Table"
    Environment = "shared"
  }
}

# Outputs to use in backend configuration
output "s3_bucket_name" {
  description = "Name of the S3 bucket for state storage"
  value       = aws_s3_bucket.terraform_state.id
}

output "dynamodb_table_name" {
  description = "Name of the DynamoDB table for state locking"
  value       = aws_dynamodb_table.terraform_locks.id
}

# ============================================
# STEP 2: CONFIGURE BACKEND IN YOUR MAIN PROJECT
# ============================================

# terraform.tf or backend.tf
# Add this to your main Terraform configuration

terraform {
  required_version = ">= 1.0"

  backend "s3" {
    bucket         = "my-terraform-state-bucket-12345"  # From step 1
    key            = "project-name/terraform.tfstate"   # Path within bucket
    region         = "us-east-1"
    dynamodb_table = "terraform-state-locks"            # From step 1
    encrypt        = true
  }

  required_providers {
    aws = {
      source  = "hashicorp/aws"
      version = "~> 5.0"
    }
  }
}

# ============================================
# STEP 3: COMMANDS TO MIGRATE TO REMOTE BACKEND
# ============================================

# After creating the S3 bucket and DynamoDB table (Step 1):
# 1. Apply the backend resources:
#    $ terraform init
#    $ terraform apply

# 2. Add the backend configuration to your main project (Step 2)

# 3. Reinitialize to migrate state to remote backend:
#    $ terraform init -migrate-state

# You'll see a prompt like:
# "Do you want to copy existing state to the new backend?"
# Type 'yes' to migrate

# Alternative: Force reconfiguration without prompt
#    $ terraform init -reconfigure -migrate-state

# ============================================
# VERIFICATION COMMANDS
# ============================================

# Verify backend configuration:
#    $ terraform init

# Check current backend:
#    $ terraform state list

# View state file location (should show S3):
#    $ terraform show

# ============================================
# MULTIPLE ENVIRONMENTS PATTERN
# ============================================

# For different environments, use different state files:

# backend-dev.tf
terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket-12345"
    key            = "dev/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-state-locks"
    encrypt        = true
  }
}

# backend-staging.tf
terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket-12345"
    key            = "staging/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-state-locks"
    encrypt        = true
  }
}

# backend-prod.tf
terraform {
  backend "s3" {
    bucket         = "my-terraform-state-bucket-12345"
    key            = "prod/terraform.tfstate"
    region         = "us-east-1"
    dynamodb_table = "terraform-state-locks"
    encrypt        = true
  }
}

# ============================================
# ALTERNATIVE: USING BACKEND CONFIG FILE
# ============================================

# backend.tf (partial configuration)
terraform {
  backend "s3" {
    # Configuration provided via backend-config.hcl or CLI
  }
}

# backend-config.hcl
bucket         = "my-terraform-state-bucket-12345"
key            = "project-name/terraform.tfstate"
region         = "us-east-1"
dynamodb_table = "terraform-state-locks"
encrypt        = true

# Initialize with config file:
#    $ terraform init -backend-config=backend-config.hcl

# ============================================
# IMPORTANT NOTES
# ============================================

# 1. S3 bucket name must be globally unique across ALL AWS accounts
# 2. The S3 bucket should be in the same region you're working in
# 3. State locking prevents concurrent modifications (critical for teams!)
# 4. Never commit terraform.tfstate to git when using remote backend
# 5. The backend resources themselves use local state (chicken-egg problem)
# 6. Consider using a separate AWS account or isolated setup for backend resources